{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will train a conditional wgan on svhn dataset\n",
    "# we will use the gradient penalty to stabilize the training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters for the dataset and the MOdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters etc.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 1\n",
    "FEATURES_CRITIC = 16\n",
    "FEATURES_GEN = 16\n",
    "CRITIC_ITERATIONS = 5\n",
    "LAMBDA_GP = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we will use SVHN dataset for this example\n",
    "### we will combine the train, test and extra datasets to make a bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: dataset_svhm/train_32x32.mat\n",
      "Using downloaded and verified file: dataset_svhm/test_32x32.mat\n",
      "Using downloaded and verified file: dataset_svhm/extra_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "#get the dataset\n",
    "#train part of svhn\n",
    "train_dataset = datasets.SVHN(root=\"dataset_svhm/\", split='train', transform=transforms, download=True)\n",
    "#test part of svhn\n",
    "test_dataset = datasets.SVHN(root=\"dataset_svhm/\", split='test', transform=transforms, download=True)\n",
    "#extra part of svhn\n",
    "extra_dataset = datasets.SVHN(root=\"dataset_svhm/\", split='extra', transform=transforms, download=True)\n",
    "#concatenate the train, test and extra dataset\n",
    "dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset, extra_dataset])\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630420\n",
      "torch.Size([3, 64, 64])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#print the total number of images in the dataset\n",
    "print(len(dataset))\n",
    "# print the shape of the images\n",
    "print(dataset[0][0].shape)\n",
    "# print the label of the image\n",
    "print(dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Input: N x channels_noise x 1 x 1\n",
    "            self.block_architecture_generator(channels_noise, features_g * 16, 4, 1, 0),  # img: 4x4\n",
    "            self.block_architecture_generator(features_g * 16, features_g * 8, 4, 2, 1),  # img: 8x8\n",
    "            self.block_architecture_generator(features_g * 8, features_g * 4, 4, 2, 1),  # img: 16x16\n",
    "            self.block_architecture_generator(features_g * 4, features_g * 2, 4, 2, 1),  # img: 32x32\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            # Output: N x channels_img x 64 x 64\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def block_architecture_generator(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            # input: N x channels_img x 64 x 64\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            self.block_architecture_critic(features_d, features_d * 2, 4, 2, 1),\n",
    "            self.block_architecture_critic(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self.block_architecture_critic(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            # After all _block img output is 4x4 (Conv2d below makes into 1x1)\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "        )\n",
    "\n",
    "    def block_architecture_critic(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize gen and critic\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializate optimizer\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inintialize tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tensorboard plotting\n",
    "fixed_noise = torch.randn(100, Z_DIM, 1, 1).to(device)\n",
    "#plot loss of generator and critic\n",
    "writer_loss = SummaryWriter(f\"runs/conditional_WGAN/loss\")\n",
    "writer_real = SummaryWriter(f\"logs/conditional_WGAN/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/conditional_WGAN/fake\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(128, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gradient penalty function for WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1] Batch 100/9851                   Loss D: -55.8379, loss G: 44.9305\n",
      "Epoch [0/1] Batch 200/9851                   Loss D: -69.6663, loss G: 80.7570\n",
      "Epoch [0/1] Batch 300/9851                   Loss D: -51.9374, loss G: 107.8354\n",
      "Epoch [0/1] Batch 400/9851                   Loss D: -36.5594, loss G: 132.8058\n",
      "Epoch [0/1] Batch 500/9851                   Loss D: -46.3237, loss G: 150.9261\n",
      "Epoch [0/1] Batch 600/9851                   Loss D: -45.5233, loss G: 162.4883\n",
      "Epoch [0/1] Batch 700/9851                   Loss D: -36.0344, loss G: 162.1082\n",
      "Epoch [0/1] Batch 800/9851                   Loss D: -31.0289, loss G: 171.5005\n",
      "Epoch [0/1] Batch 900/9851                   Loss D: -31.2241, loss G: 172.8750\n",
      "Epoch [0/1] Batch 1000/9851                   Loss D: -13.3897, loss G: 163.6735\n",
      "Epoch [0/1] Batch 1100/9851                   Loss D: -13.0480, loss G: 153.9199\n",
      "Epoch [0/1] Batch 1200/9851                   Loss D: -13.3457, loss G: 134.1922\n",
      "Epoch [0/1] Batch 1300/9851                   Loss D: -14.2663, loss G: 141.0924\n",
      "Epoch [0/1] Batch 1400/9851                   Loss D: -11.2206, loss G: 136.0737\n",
      "Epoch [0/1] Batch 1500/9851                   Loss D: -9.2428, loss G: 135.9218\n",
      "Epoch [0/1] Batch 1600/9851                   Loss D: -11.2422, loss G: 128.6157\n",
      "Epoch [0/1] Batch 1700/9851                   Loss D: -9.6091, loss G: 131.1429\n",
      "Epoch [0/1] Batch 1800/9851                   Loss D: -9.4000, loss G: 124.6364\n",
      "Epoch [0/1] Batch 1900/9851                   Loss D: -9.8106, loss G: 126.2182\n",
      "Epoch [0/1] Batch 2000/9851                   Loss D: -10.4593, loss G: 122.0489\n",
      "Epoch [0/1] Batch 2100/9851                   Loss D: -10.1225, loss G: 121.1310\n",
      "Epoch [0/1] Batch 2200/9851                   Loss D: -12.3939, loss G: 135.8474\n",
      "Epoch [0/1] Batch 2300/9851                   Loss D: -10.8722, loss G: 125.5588\n",
      "Epoch [0/1] Batch 2400/9851                   Loss D: -8.3697, loss G: 131.3006\n",
      "Epoch [0/1] Batch 2500/9851                   Loss D: -9.4081, loss G: 131.1327\n",
      "Epoch [0/1] Batch 2600/9851                   Loss D: -8.8758, loss G: 127.5904\n",
      "Epoch [0/1] Batch 2700/9851                   Loss D: -11.2111, loss G: 128.5561\n",
      "Epoch [0/1] Batch 2800/9851                   Loss D: -9.2768, loss G: 133.9187\n",
      "Epoch [0/1] Batch 2900/9851                   Loss D: -9.7330, loss G: 128.8645\n",
      "Epoch [0/1] Batch 3000/9851                   Loss D: -10.1199, loss G: 131.4778\n",
      "Epoch [0/1] Batch 3100/9851                   Loss D: -7.1681, loss G: 130.6516\n",
      "Epoch [0/1] Batch 3200/9851                   Loss D: -8.0817, loss G: 133.5173\n",
      "Epoch [0/1] Batch 3300/9851                   Loss D: -11.3325, loss G: 126.0168\n",
      "Epoch [0/1] Batch 3400/9851                   Loss D: -11.3802, loss G: 126.9829\n",
      "Epoch [0/1] Batch 3500/9851                   Loss D: -9.0147, loss G: 130.9962\n",
      "Epoch [0/1] Batch 3600/9851                   Loss D: -8.3731, loss G: 135.0228\n",
      "Epoch [0/1] Batch 3700/9851                   Loss D: -8.1357, loss G: 133.8144\n",
      "Epoch [0/1] Batch 3800/9851                   Loss D: -8.0771, loss G: 128.3438\n",
      "Epoch [0/1] Batch 3900/9851                   Loss D: -8.2933, loss G: 130.9252\n",
      "Epoch [0/1] Batch 4000/9851                   Loss D: -7.0138, loss G: 131.7369\n",
      "Epoch [0/1] Batch 4100/9851                   Loss D: -7.4013, loss G: 128.0481\n",
      "Epoch [0/1] Batch 4200/9851                   Loss D: -6.5637, loss G: 126.5566\n",
      "Epoch [0/1] Batch 4300/9851                   Loss D: -7.7615, loss G: 130.1114\n",
      "Epoch [0/1] Batch 4400/9851                   Loss D: -7.8621, loss G: 122.2872\n",
      "Epoch [0/1] Batch 4500/9851                   Loss D: -8.4776, loss G: 122.2555\n",
      "Epoch [0/1] Batch 4600/9851                   Loss D: -7.7304, loss G: 124.6963\n",
      "Epoch [0/1] Batch 4700/9851                   Loss D: -6.3703, loss G: 128.8250\n",
      "Epoch [0/1] Batch 4800/9851                   Loss D: -7.3697, loss G: 118.5604\n",
      "Epoch [0/1] Batch 4900/9851                   Loss D: -6.6960, loss G: 127.0416\n",
      "Epoch [0/1] Batch 5000/9851                   Loss D: -6.1656, loss G: 122.6595\n",
      "Epoch [0/1] Batch 5100/9851                   Loss D: -7.7423, loss G: 119.7907\n",
      "Epoch [0/1] Batch 5200/9851                   Loss D: -7.5382, loss G: 121.9035\n",
      "Epoch [0/1] Batch 5300/9851                   Loss D: -7.8213, loss G: 124.3926\n",
      "Epoch [0/1] Batch 5400/9851                   Loss D: -6.9241, loss G: 131.2694\n",
      "Epoch [0/1] Batch 5500/9851                   Loss D: -6.4346, loss G: 119.6371\n",
      "Epoch [0/1] Batch 5600/9851                   Loss D: -6.3718, loss G: 122.5342\n",
      "Epoch [0/1] Batch 5700/9851                   Loss D: -5.7329, loss G: 118.7258\n",
      "Epoch [0/1] Batch 5800/9851                   Loss D: -6.7554, loss G: 122.3329\n",
      "Epoch [0/1] Batch 5900/9851                   Loss D: -5.9942, loss G: 121.8389\n",
      "Epoch [0/1] Batch 6000/9851                   Loss D: -6.0169, loss G: 128.0561\n",
      "Epoch [0/1] Batch 6100/9851                   Loss D: -7.3805, loss G: 125.4092\n",
      "Epoch [0/1] Batch 6200/9851                   Loss D: -8.0666, loss G: 109.5515\n",
      "Epoch [0/1] Batch 6300/9851                   Loss D: -6.1154, loss G: 116.8658\n",
      "Epoch [0/1] Batch 6400/9851                   Loss D: -5.0294, loss G: 112.1761\n",
      "Epoch [0/1] Batch 6500/9851                   Loss D: -6.3019, loss G: 117.0353\n",
      "Epoch [0/1] Batch 6600/9851                   Loss D: -7.5649, loss G: 110.5937\n",
      "Epoch [0/1] Batch 6700/9851                   Loss D: -6.9591, loss G: 113.8919\n",
      "Epoch [0/1] Batch 6800/9851                   Loss D: -6.8196, loss G: 117.5204\n",
      "Epoch [0/1] Batch 6900/9851                   Loss D: -7.2316, loss G: 118.4542\n",
      "Epoch [0/1] Batch 7000/9851                   Loss D: -4.8962, loss G: 118.7417\n",
      "Epoch [0/1] Batch 7100/9851                   Loss D: -5.3391, loss G: 124.3232\n",
      "Epoch [0/1] Batch 7200/9851                   Loss D: -5.0345, loss G: 124.9671\n",
      "Epoch [0/1] Batch 7300/9851                   Loss D: -4.7824, loss G: 113.8286\n",
      "Epoch [0/1] Batch 7400/9851                   Loss D: -5.8466, loss G: 122.5589\n",
      "Epoch [0/1] Batch 7500/9851                   Loss D: -4.5563, loss G: 109.2881\n",
      "Epoch [0/1] Batch 7600/9851                   Loss D: -5.6370, loss G: 116.5613\n",
      "Epoch [0/1] Batch 7700/9851                   Loss D: -6.7354, loss G: 112.5385\n",
      "Epoch [0/1] Batch 7800/9851                   Loss D: -6.9302, loss G: 115.9698\n",
      "Epoch [0/1] Batch 7900/9851                   Loss D: -7.6237, loss G: 106.2976\n",
      "Epoch [0/1] Batch 8000/9851                   Loss D: -5.4162, loss G: 111.0712\n",
      "Epoch [0/1] Batch 8100/9851                   Loss D: -5.8159, loss G: 106.9824\n",
      "Epoch [0/1] Batch 8200/9851                   Loss D: -5.4473, loss G: 113.6703\n",
      "Epoch [0/1] Batch 8300/9851                   Loss D: -5.4625, loss G: 114.4279\n",
      "Epoch [0/1] Batch 8400/9851                   Loss D: -6.6154, loss G: 111.4715\n",
      "Epoch [0/1] Batch 8500/9851                   Loss D: -6.7941, loss G: 118.8240\n",
      "Epoch [0/1] Batch 8600/9851                   Loss D: -6.6618, loss G: 117.1914\n",
      "Epoch [0/1] Batch 8700/9851                   Loss D: -5.6280, loss G: 116.7944\n",
      "Epoch [0/1] Batch 8800/9851                   Loss D: -6.7449, loss G: 118.0196\n",
      "Epoch [0/1] Batch 8900/9851                   Loss D: -6.4305, loss G: 107.8313\n",
      "Epoch [0/1] Batch 9000/9851                   Loss D: -4.6061, loss G: 111.4341\n",
      "Epoch [0/1] Batch 9100/9851                   Loss D: -5.6255, loss G: 115.2058\n",
      "Epoch [0/1] Batch 9200/9851                   Loss D: -7.2577, loss G: 107.2674\n",
      "Epoch [0/1] Batch 9300/9851                   Loss D: -6.2085, loss G: 113.6968\n",
      "Epoch [0/1] Batch 9400/9851                   Loss D: -6.3660, loss G: 110.7823\n",
      "Epoch [0/1] Batch 9500/9851                   Loss D: -6.6161, loss G: 106.5781\n",
      "Epoch [0/1] Batch 9600/9851                   Loss D: -6.1767, loss G: 116.2187\n",
      "Epoch [0/1] Batch 9700/9851                   Loss D: -5.5827, loss G: 110.7467\n",
      "Epoch [0/1] Batch 9800/9851                   Loss D: -5.4208, loss G: 109.4088\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.shape[0]\n",
    "\n",
    "        # Train Critic: max E[critic(real)] - E[critic(fake)]\n",
    "        # equivalent to minimizing the negative of that\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            critic_real = critic(real).reshape(-1)\n",
    "            critic_fake = critic(fake).reshape(-1)\n",
    "            gp = gradient_penalty(critic, real, fake, device=device)\n",
    "            loss_critic = (\n",
    "                -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp\n",
    "            )\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "        gen_fake = critic(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
    "                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sudo fuser -k /dev/nvidia\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "079402cc50f681fca3bc4b588c8594ae5b0127c6215ec7c89d21fdfb87f97274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
