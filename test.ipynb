{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch and tensorb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  sudo fuser -k /dev/nvidia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loop over disc.0.weight\n",
    "# for name, param in critic.named_parameters():\n",
    "#     if name == \"disc.0.weight\":\n",
    "#         #print the gradient of the layer\n",
    "#         print(name, param.grad)\n",
    "#         #print norm of the gradient of the layer\n",
    "#         print(torch.norm(param.grad))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #save the trained model\n",
    "# torch.save(gen.state_dict(), \"trained_models/WGAN3/gen.pth\")\n",
    "# torch.save(critic.state_dict(), \"trained_models/WGAN3/critic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print critic model\n",
    "print(critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loop over gradients of all layers of critic\n",
    "for name, param in critic.named_parameters():\n",
    "    #print the gradient of the layer\n",
    "    print(name, param.grad)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in critic.named_parameters():\n",
    "            if name == \"0.weight\":\n",
    "                print(\"Critic Gradient w.r.t 1st layer\", param.grad.norm())\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over disc.0.weight\n",
    "for name, param in critic.named_parameters():\n",
    "    if name == \"disc.2.0.weight\":\n",
    "        #print the gradient of the layer\n",
    "        print(name, param.grad)\n",
    "        #print norm of the gradient of the layer\n",
    "        print(torch.norm(param.grad))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze gradient of first layer of critic\n",
    "# for name, param in critic.named_parameters():\n",
    "#     if name == \"conv1.weight\":\n",
    "#         print(\"inside loop\")\n",
    "#         print(param.grad)\n",
    "#         print(\"conv1.weight\", param.grad, global_step=step)\n",
    "#loop over parameters in critic[0].weight.grad\n",
    "for i in range(0, len(critic[0].weight.grad)):\n",
    "    for j in range(0, len(critic[0].weight.grad[i])):\n",
    "        print(\"critic[0].weight.grad\", critic[0].weight.grad[i][j])\n",
    "        # (\"critic[0].weight.grad\", critic[0].weight.grad[i][j], global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from ignite.metrics.gan import FID\n",
    "import torchvision.transforms as transforms\n",
    "#import Image from PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = FID()\n",
    "\n",
    "y_pred, y = torch.rand(100, 3, 64, 64), torch.rand(100, 3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(batch):\n",
    "    arr = []\n",
    "    for img in batch:\n",
    "        pil_img = transforms.ToPILImage()(img)\n",
    "        resized_img = pil_img.resize((299,299), Image.BILINEAR)\n",
    "        arr.append(transforms.ToTensor()(resized_img))\n",
    "    return torch.stack(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10827/3336813213.py:5: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  resized_img = pil_img.resize((299,299), Image.BILINEAR)\n"
     ]
    }
   ],
   "source": [
    "y_pred = interpolate(y_pred)\n",
    "y = interpolate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignite batch FID 6.449859458128706e-05\n"
     ]
    }
   ],
   "source": [
    "# print('ignite online FID', m.compute())  # 8.98434690701287e-05\n",
    "\n",
    "# m = FID()\n",
    "m.update((y_pred, y))\n",
    "\n",
    "print('ignite batch FID', m.compute())  # 8.98434072559458e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignite batch FID 4.549401584859553e-05\n"
     ]
    }
   ],
   "source": [
    "# print('ignite online FID', m.compute())  # 8.98434690701287e-05\n",
    "\n",
    "# m = FID()\n",
    "m.update((y_pred, y))\n",
    "m.update((y_pred, y))\n",
    "print('ignite batch FID', m.compute())  # 8.98434072559458e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#Y102sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mignite batch FID\u001b[39m\u001b[39m'\u001b[39m, m\u001b[39m.\u001b[39;49mcompute())\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ignite/metrics/metric.py:577\u001b[0m, in \u001b[0;36msync_all_reduce.<locals>.wrapper.<locals>.another_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_reduced \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ignite/metrics/gan/fid.py:259\u001b[0m, in \u001b[0;36mFID.compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39m@sync_all_reduce\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m_num_examples\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_train_total\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_test_total\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_train_sigma\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_test_sigma\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m--> 259\u001b[0m     fid \u001b[39m=\u001b[39m fid_score(\n\u001b[1;32m    260\u001b[0m         mu1\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_total \u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_examples,\n\u001b[1;32m    261\u001b[0m         mu2\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_total \u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_examples,\n\u001b[1;32m    262\u001b[0m         sigma1\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_covariance(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_sigma, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_total),\n\u001b[1;32m    263\u001b[0m         sigma2\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_covariance(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_sigma, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_total),\n\u001b[1;32m    264\u001b[0m         eps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_eps,\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39misnan(torch\u001b[39m.\u001b[39mtensor(fid)) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(torch\u001b[39m.\u001b[39mtensor(fid)):\n\u001b[1;32m    268\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe product of covariance of train and test features is out of bounds.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ignite/metrics/gan/fid.py:41\u001b[0m, in \u001b[0;36mfid_score\u001b[0;34m(mu1, mu2, sigma1, sigma2, eps)\u001b[0m\n\u001b[1;32m     38\u001b[0m diff \u001b[39m=\u001b[39m mu1 \u001b[39m-\u001b[39m mu2\n\u001b[1;32m     40\u001b[0m \u001b[39m# Product might be almost singular\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m covmean, _ \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49msqrtm(sigma1\u001b[39m.\u001b[39;49mmm(sigma2), disp\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     42\u001b[0m \u001b[39m# Numerical error might give slight imaginary component\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39miscomplexobj(covmean):\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/scipy/linalg/_matfuncs_sqrtm.py:158\u001b[0m, in \u001b[0;36msqrtm\u001b[0;34m(A, disp, blocksize)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msqrtm\u001b[39m(A, disp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, blocksize\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m):\n\u001b[1;32m    115\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m    Matrix square root.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     A \u001b[39m=\u001b[39m _asarray_validated(A, check_finite\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, as_inexact\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(A\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    160\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNon-matrix input to matrix function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/scipy/_lib/_util.py:293\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mmasked arrays are not supported\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    292\u001b[0m toarray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray_chkfinite \u001b[39mif\u001b[39;00m check_finite \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39masarray\n\u001b[0;32m--> 293\u001b[0m a \u001b[39m=\u001b[39m toarray(a)\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m objects_ok:\n\u001b[1;32m    295\u001b[0m     \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mdtype(\u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/numpy/lib/function_base.py:488\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    486\u001b[0m a \u001b[39m=\u001b[39m asarray(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[1;32m    487\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mchar \u001b[39min\u001b[39;00m typecodes[\u001b[39m'\u001b[39m\u001b[39mAllFloat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(a)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    489\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marray must not contain infs or NaNs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    490\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "print('ignite batch FID', m.compute()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the metric\n",
    "m.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import IS inception score from ignite\n",
    "from ignite.metrics.gan.inception_score import InceptionScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n  = InceptionScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10827/3336813213.py:5: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  resized_img = pil_img.resize((299,299), Image.BILINEAR)\n"
     ]
    }
   ],
   "source": [
    "y_pred = interpolate(y_pred)\n",
    "y = interpolate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# print('ignite online FID', m.compute())  # 8.98434690701287e-05\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# m = FID()\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m n\u001b[39m.\u001b[39;49mupdate((y_pred, y))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ignite/metrics/metric.py:596\u001b[0m, in \u001b[0;36mreinit__is_reduced.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m: Metric, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_reduced \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ignite/metrics/gan/inception_score.py:114\u001b[0m, in \u001b[0;36mInceptionScore.update\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m@reinit__is_reduced\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate\u001b[39m(\u001b[39mself\u001b[39m, output: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     probabilities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_features(output)\n\u001b[1;32m    116\u001b[0m     prob_sum \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(probabilities, \u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    117\u001b[0m     log_prob \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(probabilities \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eps)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ignite/metrics/gan/utils.py:95\u001b[0m, in \u001b[0;36m_BaseInceptionMetric._extract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_extract_features\u001b[39m(\u001b[39mself\u001b[39m, inputs: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 95\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mdetach()\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m inputs\u001b[39m.\u001b[39mdevice \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device):\n\u001b[1;32m     98\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "# print('ignite online FID', m.compute())  # 8.98434690701287e-05\n",
    "\n",
    "# m = FID()\n",
    "n.update((y_pred, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ignite batch FID', n.compute())  # 8.98434072559458e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(n\u001b[39m.\u001b[39;49mcompute(y, y_pred))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/ignite/metrics/metric.py:577\u001b[0m, in \u001b[0;36msync_all_reduce.<locals>.wrapper.<locals>.another_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_reduced \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: compute() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "print(n.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_fid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mignite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgan\u001b[39;00m \u001b[39mimport\u001b[39;00m FID\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_fid\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception\u001b[39;00m \u001b[39mimport\u001b[39;00m InceptionV3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m dims \u001b[39m=\u001b[39m \u001b[39m2048\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_fid'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from ignite.metrics.gan import FID\n",
    "\n",
    "from pytorch_fid.inception import InceptionV3\n",
    "\n",
    "device = \"cpu\"\n",
    "dims = 2048\n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "model = InceptionV3([block_idx]).to(device)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class WrapperInceptionV3(nn.Module):\n",
    "    \n",
    "    def __init__(self, fid_incv3):\n",
    "        super().__init__()\n",
    "        self.fid_incv3 = fid_incv3\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        y = self.fid_incv3(x)\n",
    "        y = y[0]\n",
    "        y = y[:, :, 0, 0]\n",
    "        return y\n",
    "\n",
    "wrapper_model = WrapperInceptionV3(model)\n",
    "wrapper_model.eval();\n",
    "\n",
    "m = FID(num_features=dims, feature_extractor=wrapper_model)\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "y_pred, y = torch.rand(100, 3, 299, 299), torch.rand(100, 3, 299, 299)\n",
    "\n",
    "  \n",
    "m.update((y_pred, y))\n",
    "\n",
    "print('ignite online FID', m.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.metrics import FID, InceptionScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch ignite for importing FID\n",
    "#we will use the FID score to evaluate the quality of the generated images\n",
    "import ignite\n",
    "#import FID\n",
    "from ignite.metrics import FID\n",
    "#import default_evaluator\n",
    "from ignite.engine import Engine\n",
    "from ignite.metrics.metric import EpochWise, Metric, MetricUsage\n",
    "import ignite.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.64.35.99/home/lisa/bhartendu/adrl/Assignment1/conditional_gan/test.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m fid_metric \u001b[39m=\u001b[39m FID(device\u001b[39m=\u001b[39mdevice)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "fid_metric = FID(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_metric = InceptionScore(device=device, output_transform=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(batch):\n",
    "    arr = []\n",
    "    for img in batch:\n",
    "        pil_img = transforms.ToPILImage()(img)\n",
    "        resized_img = pil_img.resize((299,299), Image.BILINEAR)\n",
    "        arr.append(transforms.ToTensor()(resized_img))\n",
    "    return torch.stack(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.ones(10, 4)\n",
    "y_pred = torch.ones(10, 4)\n",
    "#move to gpu\n",
    "y_true = y_true.to(device)\n",
    "y_pred = y_pred.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_metric(y_pred , y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class InceptionV3(nn.Module):\n",
    "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
    "\n",
    "    # Index of default block of inception to return,\n",
    "    # corresponds to output of final average pooling\n",
    "    DEFAULT_BLOCK_INDEX = 3\n",
    "\n",
    "    # Maps feature dimensionality to their output blocks indices\n",
    "    BLOCK_INDEX_BY_DIM = {\n",
    "        64: 0,   # First max pooling features\n",
    "        192: 1,  # Second max pooling featurs\n",
    "        768: 2,  # Pre-aux classifier features\n",
    "        2048: 3  # Final average pooling features\n",
    "    }\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_blocks=[DEFAULT_BLOCK_INDEX],\n",
    "                 resize_input=True,\n",
    "                 normalize_input=True,\n",
    "                 requires_grad=False):\n",
    "        \n",
    "        super(InceptionV3, self).__init__()\n",
    "\n",
    "        self.resize_input = resize_input\n",
    "        self.normalize_input = normalize_input\n",
    "        self.output_blocks = sorted(output_blocks)\n",
    "        self.last_needed_block = max(output_blocks)\n",
    "\n",
    "        assert self.last_needed_block <= 3, \\\n",
    "            'Last possible output block index is 3'\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        \n",
    "        inception = models.inception_v3(pretrained=True)\n",
    "\n",
    "        # Block 0: input to maxpool1\n",
    "        block0 = [\n",
    "            inception.Conv2d_1a_3x3,\n",
    "            inception.Conv2d_2a_3x3,\n",
    "            inception.Conv2d_2b_3x3,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        ]\n",
    "        self.blocks.append(nn.Sequential(*block0))\n",
    "\n",
    "        # Block 1: maxpool1 to maxpool2\n",
    "        if self.last_needed_block >= 1:\n",
    "            block1 = [\n",
    "                inception.Conv2d_3b_1x1,\n",
    "                inception.Conv2d_4a_3x3,\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block1))\n",
    "\n",
    "        # Block 2: maxpool2 to aux classifier\n",
    "        if self.last_needed_block >= 2:\n",
    "            block2 = [\n",
    "                inception.Mixed_5b,\n",
    "                inception.Mixed_5c,\n",
    "                inception.Mixed_5d,\n",
    "                inception.Mixed_6a,\n",
    "                inception.Mixed_6b,\n",
    "                inception.Mixed_6c,\n",
    "                inception.Mixed_6d,\n",
    "                inception.Mixed_6e,\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block2))\n",
    "\n",
    "        # Block 3: aux classifier to final avgpool\n",
    "        if self.last_needed_block >= 3:\n",
    "            block3 = [\n",
    "                inception.Mixed_7a,\n",
    "                inception.Mixed_7b,\n",
    "                inception.Mixed_7c,\n",
    "                nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "            ]\n",
    "            self.blocks.append(nn.Sequential(*block3))\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \"\"\"Get Inception feature maps\n",
    "        Parameters\n",
    "        ----------\n",
    "        inp : torch.autograd.Variable\n",
    "            Input tensor of shape Bx3xHxW. Values are expected to be in\n",
    "            range (0, 1)\n",
    "        Returns\n",
    "        -------\n",
    "        List of torch.autograd.Variable, corresponding to the selected output\n",
    "        block, sorted ascending by index\n",
    "        \"\"\"\n",
    "        outp = []\n",
    "        x = inp\n",
    "\n",
    "        if self.resize_input:\n",
    "            x = interpolate(x)\n",
    "\n",
    "        if self.normalize_input:\n",
    "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
    "\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if idx in self.output_blocks:\n",
    "                outp.append(x)\n",
    "\n",
    "            if idx == self.last_needed_block:\n",
    "                break\n",
    "\n",
    "        return outp\n",
    "    \n",
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "model = InceptionV3([block_idx])\n",
    "model=model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activation_statistics(images,model,batch_size=128, dims=2048,\n",
    "                    cuda=False):\n",
    "    model.eval()\n",
    "    act=np.empty((len(images), dims))\n",
    "    \n",
    "    if cuda:\n",
    "        batch=images.cuda()\n",
    "    else:\n",
    "        batch=images\n",
    "    pred = model(batch)[0]\n",
    "\n",
    "        # If model output is not scalar, apply global spatial average pooling.\n",
    "        # This happens if you choose a dimensionality not equal 2048.\n",
    "    if pred.size(2) != 1 or pred.size(3) != 1:\n",
    "        pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "\n",
    "    act= pred.cpu().data.numpy().reshape(pred.size(0), -1)\n",
    "    \n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    \"\"\"Numpy implementation of the Frechet Distance.\n",
    "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
    "    and X_2 ~ N(mu_2, C_2) is\n",
    "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
    "    \"\"\"\n",
    "\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    \n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    \n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fretchet(images_real,images_fake,model):\n",
    "     mu_1,std_1=calculate_activation_statistics(images_real,model,cuda=True)\n",
    "     mu_2,std_2=calculate_activation_statistics(images_fake,model,cuda=True)\n",
    "    \n",
    "     \"\"\"get fretched distance\"\"\"\n",
    "     fid_value = calculate_frechet_distance(mu_1, std_1, mu_2, std_2)\n",
    "     return fid_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fretchet_dist=calculate_fretchet(y_pred , y_true,model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return FID score using ignite package\n",
    "def fid_score(real_images,fake_images,device=device):\n",
    "    # calculate the FID score\n",
    "    fid = FID()\n",
    "    fid.attach(default_evaluator, name='fid')\n",
    "\n",
    "    #calculate the FID score\n",
    "    score = default_evaluator.run([[fake_images, real_images]])\n",
    "    return score.metrics['fid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the FID score\n",
    "y_true = torch.ones(10, 4)\n",
    "y_pred = torch.ones(10, 4)\n",
    "fid_score(y_true,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test calculate_frechet_distance\n",
    "calculate_frechet_distance(1, 1, 1, 1, eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "079402cc50f681fca3bc4b588c8594ae5b0127c6215ec7c89d21fdfb87f97274"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
